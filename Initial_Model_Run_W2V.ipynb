{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Setup nltk corpora path and Google Word2Vec location\n",
    "google_vec_file = r\"C:\\Users\\moham\\Metis Bootcamp\\GoogleNewsVectors\\GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)\n",
    "\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Corpus of News Article Text\n",
    "with open('./data/news_data_frame_reduced_preprocessed.pickle', 'rb') as file:\n",
    "    news_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/grams/token_unigram_text\",'rb')  \n",
    "uni_lem_comb2 = pickle.load(fileObject)  ## load unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/grams/bigram_text\",'rb')  \n",
    "bi_lem_comb2 = pickle.load(fileObject)  ## load unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/grams/trigram_text\",'rb')  \n",
    "tri_lem_comb2 = pickle.load(fileObject)  ## load unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ban, united, states, companies, selling, part...\n",
       "1    [washington, hatice, cengiz, fiancee, murdered...\n",
       "2    [least, six, civilians, including, women, chil...\n",
       "3    [monday, may, photo, juliet, fine, principal, ...\n",
       "4    [file, feb, file, photo, sen, doug, jones, ala...\n",
       "5    [new, york, mayor, bill, blasio, arrives, offi...\n",
       "6    [file, feb, file, photo, shows, oxycontin, pil...\n",
       "7    [booking, photo, provided, chicago, police, de...\n",
       "8    [file, friday, april, file, photo, far, right,...\n",
       "9    [venezuela, opposition, leader, self, proclaim...\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_lem = pd.Series([x for x in uni_lem_comb2])\n",
    "uni_lem[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ban united_states companies selling parts huaw...\n",
       "1    washington hatice cengiz fiancee murdered saud...\n",
       "2    least_six civilians including women_children k...\n",
       "3    monday may photo juliet fine principal beverly...\n",
       "4    file_feb file_photo sen doug jones ala questio...\n",
       "5    new_york mayor_bill blasio arrives official de...\n",
       "6    file_feb file_photo shows oxycontin pills arra...\n",
       "7    booking photo provided chicago_police departme...\n",
       "8    file friday april file_photo far_right vox par...\n",
       "9    venezuela opposition_leader self_proclaimed in...\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lem = pd.Series([x for x in bi_lem_comb2])\n",
    "bi_lem[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ban united_states companies selling parts huaw...\n",
       "1    washington hatice cengiz fiancee murdered saud...\n",
       "2    least_six civilians including women_children k...\n",
       "3    monday may_photo juliet fine principal beverly...\n",
       "4    file_feb_file_photo sen doug jones ala questio...\n",
       "5    new_york mayor_bill blasio arrives official de...\n",
       "6    file_feb_file_photo shows oxycontin pills arra...\n",
       "7    booking photo provided chicago_police departme...\n",
       "8    file friday april file_photo far_right vox par...\n",
       "9    venezuela opposition_leader self_proclaimed in...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_lem = pd.Series([x for x in tri_lem_comb2])\n",
    "tri_lem[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the Text into Trigram Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vector(text):\n",
    "    text = text.split()\n",
    "    vector = []\n",
    "    for i in text:\n",
    "        try:\n",
    "            vector.append(model.word_vec(i))\n",
    "        except:\n",
    "            pass\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text_tri = tri_lem.apply(infer_vector)\n",
    "values_of_errors = [i for i,x in enumerate(vec_text_tri) if x == []]\n",
    "bad_series = vec_text_tri.index.isin(values_of_errors)\n",
    "vector = vec_text_tri[~bad_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec_text_tri = []\n",
    "for row in vector:\n",
    "    vec_text_tri.append(np.mean(row,axis=0))\n",
    "\n",
    "vec_text_tri = pd.Series(vec_text_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.0042810584, 0.039145432, 0.03362472, 0.065...\n",
       "1    [0.010554764, 0.029965691, 0.04417438, 0.03513...\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text_tri[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text_tri = pd.DataFrame(vec_text_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec_text_tri = pd.DataFrame(vec_text_tri[0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004281</td>\n",
       "      <td>0.039145</td>\n",
       "      <td>0.033625</td>\n",
       "      <td>0.065445</td>\n",
       "      <td>-0.082601</td>\n",
       "      <td>-0.020334</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.043258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058678</td>\n",
       "      <td>0.027957</td>\n",
       "      <td>-0.056587</td>\n",
       "      <td>0.032648</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>-0.035646</td>\n",
       "      <td>0.039916</td>\n",
       "      <td>-0.020221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>0.044174</td>\n",
       "      <td>0.035132</td>\n",
       "      <td>-0.061126</td>\n",
       "      <td>-0.015194</td>\n",
       "      <td>0.055819</td>\n",
       "      <td>-0.077717</td>\n",
       "      <td>0.104377</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052899</td>\n",
       "      <td>-0.019860</td>\n",
       "      <td>-0.042446</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>-0.031552</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>-0.050903</td>\n",
       "      <td>0.037147</td>\n",
       "      <td>0.021626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027087</td>\n",
       "      <td>0.051287</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>0.043642</td>\n",
       "      <td>-0.024894</td>\n",
       "      <td>-0.021078</td>\n",
       "      <td>-0.016652</td>\n",
       "      <td>-0.107409</td>\n",
       "      <td>0.101749</td>\n",
       "      <td>0.078397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047129</td>\n",
       "      <td>-0.004740</td>\n",
       "      <td>-0.067274</td>\n",
       "      <td>0.012861</td>\n",
       "      <td>-0.052640</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>-0.011003</td>\n",
       "      <td>-0.004494</td>\n",
       "      <td>0.034060</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.046228</td>\n",
       "      <td>0.071021</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>-0.009410</td>\n",
       "      <td>0.038559</td>\n",
       "      <td>-0.073924</td>\n",
       "      <td>0.061498</td>\n",
       "      <td>0.028121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088085</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>-0.075012</td>\n",
       "      <td>0.036264</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>-0.016414</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>-0.056618</td>\n",
       "      <td>0.046487</td>\n",
       "      <td>-0.002936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.083412</td>\n",
       "      <td>-0.064150</td>\n",
       "      <td>-0.040388</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>-0.032623</td>\n",
       "      <td>0.076677</td>\n",
       "      <td>0.044590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049103</td>\n",
       "      <td>-0.006976</td>\n",
       "      <td>-0.034393</td>\n",
       "      <td>-0.010264</td>\n",
       "      <td>-0.040613</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>-0.048302</td>\n",
       "      <td>0.036808</td>\n",
       "      <td>0.033324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.004281  0.039145  0.033625  0.065445 -0.082601 -0.020334  0.024655   \n",
       "1  0.010555  0.029966  0.044174  0.035132 -0.061126 -0.015194  0.055819   \n",
       "2  0.027087  0.051287  0.044152  0.043642 -0.024894 -0.021078 -0.016652   \n",
       "3  0.027874  0.032129  0.046228  0.071021 -0.049118 -0.009410  0.038559   \n",
       "4  0.016836  0.021730  0.039434  0.083412 -0.064150 -0.040388  0.047837   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0 -0.027403  0.085103  0.043258    ...    -0.058678  0.027957 -0.056587   \n",
       "1 -0.077717  0.104377  0.079149    ...    -0.052899 -0.019860 -0.042446   \n",
       "2 -0.107409  0.101749  0.078397    ...    -0.047129 -0.004740 -0.067274   \n",
       "3 -0.073924  0.061498  0.028121    ...    -0.088085  0.001812 -0.075012   \n",
       "4 -0.032623  0.076677  0.044590    ...    -0.049103 -0.006976 -0.034393   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.032648  0.010886  0.003896  0.010895 -0.035646  0.039916 -0.020221  \n",
       "1  0.034073 -0.031552  0.005538 -0.005109 -0.050903  0.037147  0.021626  \n",
       "2  0.012861 -0.052640  0.006913 -0.011003 -0.004494  0.034060  0.021550  \n",
       "3  0.036264  0.000982 -0.016414  0.001484 -0.056618  0.046487 -0.002936  \n",
       "4 -0.010264 -0.040613 -0.004990  0.003940 -0.048302  0.036808  0.033324  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text_tri.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving vec_text of trigrams:\n",
    "filename = './data/grams/vec_text_trigram.sav'\n",
    "pickle.dump(vec_text_tri, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text and response to array \n",
    "y_response_tri = news_df.Not_Real_or_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_series_news_df = y_response_tri.index.isin(values_of_errors)\n",
    "y_response_tri = y_response_tri[~bad_series_news_df].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving y_response trigrams:\n",
    "filename = './data/grams/y_response_tri.sav'\n",
    "pickle.dump(y_response_tri, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the Text into Bigram Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text_bi = bi_lem .apply(infer_vector)\n",
    "values_of_errors = [i for i,x in enumerate(vec_text_bi) if x == []]\n",
    "bad_series = vec_text_bi.index.isin(values_of_errors)\n",
    "vector = vec_text_bi[~bad_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec_text_bi = []\n",
    "for row in vector:\n",
    "    vec_text_bi.append(np.mean(row,axis=0))\n",
    "\n",
    "vec_text_bi = pd.Series(vec_text_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.004424307, 0.039920203, 0.03196768, 0.0680...\n",
       "1    [0.010511921, 0.030049566, 0.04401093, 0.03551...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text_bi[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text_bi = pd.DataFrame(vec_text_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 280 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec_text_bi = pd.DataFrame(vec_text_bi[0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004424</td>\n",
       "      <td>0.039920</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>0.068061</td>\n",
       "      <td>-0.080996</td>\n",
       "      <td>-0.024467</td>\n",
       "      <td>0.022741</td>\n",
       "      <td>-0.030740</td>\n",
       "      <td>0.084796</td>\n",
       "      <td>0.042647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058602</td>\n",
       "      <td>0.025560</td>\n",
       "      <td>-0.059898</td>\n",
       "      <td>0.032545</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>-0.033907</td>\n",
       "      <td>0.037345</td>\n",
       "      <td>-0.019121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010512</td>\n",
       "      <td>0.030050</td>\n",
       "      <td>0.044011</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>-0.062077</td>\n",
       "      <td>-0.015621</td>\n",
       "      <td>0.057381</td>\n",
       "      <td>-0.077247</td>\n",
       "      <td>0.105612</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053423</td>\n",
       "      <td>-0.019029</td>\n",
       "      <td>-0.044617</td>\n",
       "      <td>0.034856</td>\n",
       "      <td>-0.032338</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>-0.003092</td>\n",
       "      <td>-0.052623</td>\n",
       "      <td>0.038148</td>\n",
       "      <td>0.021211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024445</td>\n",
       "      <td>0.049508</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.041442</td>\n",
       "      <td>-0.028839</td>\n",
       "      <td>-0.022661</td>\n",
       "      <td>-0.016139</td>\n",
       "      <td>-0.106955</td>\n",
       "      <td>0.101060</td>\n",
       "      <td>0.076055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050624</td>\n",
       "      <td>-0.003738</td>\n",
       "      <td>-0.064846</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>-0.051285</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>-0.012321</td>\n",
       "      <td>-0.007127</td>\n",
       "      <td>0.033073</td>\n",
       "      <td>0.027607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027942</td>\n",
       "      <td>0.033355</td>\n",
       "      <td>0.044223</td>\n",
       "      <td>0.070619</td>\n",
       "      <td>-0.048846</td>\n",
       "      <td>-0.008677</td>\n",
       "      <td>0.039634</td>\n",
       "      <td>-0.073948</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.026507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089344</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>-0.075675</td>\n",
       "      <td>0.033858</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.014960</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>-0.057620</td>\n",
       "      <td>0.044924</td>\n",
       "      <td>-0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016295</td>\n",
       "      <td>0.022985</td>\n",
       "      <td>0.037451</td>\n",
       "      <td>0.082624</td>\n",
       "      <td>-0.068564</td>\n",
       "      <td>-0.043832</td>\n",
       "      <td>0.043920</td>\n",
       "      <td>-0.029424</td>\n",
       "      <td>0.080041</td>\n",
       "      <td>0.042513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052999</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>-0.035802</td>\n",
       "      <td>-0.015378</td>\n",
       "      <td>-0.039352</td>\n",
       "      <td>-0.005778</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>-0.044876</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.036912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.004424  0.039920  0.031968  0.068061 -0.080996 -0.024467  0.022741   \n",
       "1  0.010512  0.030050  0.044011  0.035513 -0.062077 -0.015621  0.057381   \n",
       "2  0.024445  0.049508  0.042120  0.041442 -0.028839 -0.022661 -0.016139   \n",
       "3  0.027942  0.033355  0.044223  0.070619 -0.048846 -0.008677  0.039634   \n",
       "4  0.016295  0.022985  0.037451  0.082624 -0.068564 -0.043832  0.043920   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0 -0.030740  0.084796  0.042647    ...    -0.058602  0.025560 -0.059898   \n",
       "1 -0.077247  0.105612  0.081105    ...    -0.053423 -0.019029 -0.044617   \n",
       "2 -0.106955  0.101060  0.076055    ...    -0.050624 -0.003738 -0.064846   \n",
       "3 -0.073948  0.062209  0.026507    ...    -0.089344  0.001562 -0.075675   \n",
       "4 -0.029424  0.080041  0.042513    ...    -0.052999 -0.012819 -0.035802   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.032545  0.013791  0.002109  0.007907 -0.033907  0.037345 -0.019121  \n",
       "1  0.034856 -0.032338  0.003783 -0.003092 -0.052623  0.038148  0.021211  \n",
       "2  0.011221 -0.051285  0.007612 -0.012321 -0.007127  0.033073  0.027607  \n",
       "3  0.033858 -0.000062 -0.014960  0.002777 -0.057620  0.044924 -0.002511  \n",
       "4 -0.015378 -0.039352 -0.005778  0.002291 -0.044876  0.036111  0.036912  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text_bi.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving vec_text of trigrams:\n",
    "filename = './data/grams/vec_text_bigram.sav'\n",
    "pickle.dump(vec_text_bi, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text and response to array \n",
    "y_response_bi = news_df.Not_Real_or_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_series_news_df = y_response_bi.index.isin(values_of_errors)\n",
    "y_response_bi = y_response_bi[~bad_series_news_df].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving y_response trigrams:\n",
    "filename = './data/grams/y_response_bi.sav'\n",
    "pickle.dump(y_response_bi, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Corpus of News Article Text\n",
    "with open('./data/news_data_frame_reduced_preprocessed.pickle', 'rb') as file:\n",
    "    news_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/grams/vec_text_trigram.sav\",'rb')  \n",
    "vec_text_trigram= pickle.load(fileObject)  ## load unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/grams/y_response_tri.sav\",'rb')  \n",
    "y_response_tri= pickle.load(fileObject)  ## load unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/grams/vec_text_bigram.sav\",'rb')  \n",
    "vec_text_bigram = pickle.load(fileObject)  ## load unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./data/grams/y_response_bi.sav\",'rb')  \n",
    "y_response_bi = pickle.load(fileObject)  ## load unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
